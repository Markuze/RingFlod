\section{Background}
In this section, we give the motivation for our new attacks by presenting classic DMA attacks, the IOMMU protection against them, and recent attacks that circumvent it.
\subsection{DMA Attacks}
Direct Memory Access (DMA),allows input and output devices (I/O devices) to transfer data to and from memory [oC54]. While DMA is essential for fast I/O transactions, it also provides ample opportunity for unmonitored and malicious activity by the attached peripheral i.e DMA attacks. Without the presence of an IOMMU, which will be discussed later, the system has no way of preventing a DMA-capable device from reading and writing any memory region, given that DMA transactions are not filtered and use physical addresses. If a device is compromised, an attacker can read sensitive data from memory or overwrite the OS code and data-structures to gain full control of the victim system. DMA attacks can be carried out using an external or internal DMA-capable device. Using an external device for DMA attacks is rather simple if the victim system has expansion ports, such as FireWire or Thunderbolt, which allow external devices to initiate DMA transactions. By connecting a programmable accessory or a remote machine to such a port, one can read and write any of the victim machine’s memory [Dor04, Vol, MM]. In contrast, to carry out DMA attacks using internal devices, the attacker must gain control over the internal I/O device, and turn it into a malicious device that executes the attacker’s code. While using internal devices is more challenging for attackers, it allows the attacker to run long-lived and stealthy attacks. It is important to note in this context that gaining control over an I/O device does not necessarily compromise the system if DMA attacks cannot be carried out. To gain control over an I/O device, an attacker can exploit firmware bugs. These bugs can be well-known, as end-users are often slow in deploying firmware updates [DPVL10],or zero-day vulnerabilities that are found by extracting and reverse engineering the firmware [Ben17b]. Alternatively, certain attackers may be able to replace the device firmware with a malicious one [ZKB+13, NL14], or even manufacture devices that appear to be legitimate but are in fact malicious at the circuitry level [YHD+16]. Studies have demonstrated that an attacker capable of issuing DMA transactions, can initiate various attacks, ranging from running keyloggers [LKV+13, SB12] to gaining full control over commodity OSs and hypervisors, including Windows [AD10], Linux, OSX [Fri16], Android [Ben17b] and Xen [Woj08]. DMA attacks are also commonly used for computer forensics. Tools such as Volatility [Vol], Inception [MM], GoldFish [GA10] and FinFireWire [Fin14] can extract target machine memory and unlock victim machines by patching the OS code. These tools are reportedly used by law enforcement agencies. As countermeasures for DMA attacks, studies suggested software-based protection techniques. These solutions tighten security against DMA attacks but do not prevent them. Address space layout randomization (ASLR), often used to protect against buffer overflow attacks, can complicate DMA attacks, but does not prevent them [SB12]. Storing secret data in the CPU registers can prevent the secret data from being read directly by exploited devices [MFD11, CZG+15, Sim11], yet does not prevent the devices from extracting the secret by modifying the OS memory [BR12]. DMA attacks can be detected by monitoring the bus activity using hardware performance counters and finding anomalies between the expected and actual DMA activity [Ste13]. This approach, however, requires modeling each device’s DMA activity [Ste14], which is arguably unreasonable.
\subsection{IOMMU}
As software techniques cannot prevent DMA attacks, DMA access must be restricted through a hardware protection device. The most common mechanism for this purpose is the input/output memory management unit (IOMMU), which adds a level of indirection for DMA addresses [WRC08, BYXO+07, YZ15, SB12, MTF12]. The IOMMU effectively forces the device to use virtual addresses, which are then translated into physical ones, according to architectural data structures that are configurable by the OS. Usually, and specifically in the x86 architecture, access rights are set and translations are performed in page granularity [Int16b, AMD11]. Inspired by the standard MMU in x86, the translations are set in a radix tree (Figure 2.1). The IOMMU protects against DMA attacks by ignoring or faulting when devices initiate DMA transactions to virtual addresses not marked as present. To use the IOMMU for protection, the OS maps in the IOMMU only the pages that hold I/O buffers. When introduced over 40 years ago, IOMMUs were not tasked primarily with providing security [DWT79]. IOMMUs were used to allow devices that did not support vectored I/O to write to contiguous virtual memory, which is noncontiguous in physical memory [Chu96, WMM97]. IOMMUs enabled legacy devices that only supported limited address width to access high memory. More recently, IOMMUs were used to assign I/O devices directly to virtual machines while maintaining their isolation properties [Int16b, AMD11]. Throughout this period, OS developers did not appear to consider protection against malicious devices very important. To date, for example, Windows 10 is the first Windows version that uses the IOMMU for protection [Mic17].
\subsection{FireWire}
 FireWire is strongly related to DMA attacks because this is an external port that allows end devices to access DMA directly, making potential attacks much easier, and historically it was used to carry them out. For the same reasons, we used FireWire as a base of all our attacks, either by attacking its driver directly or by using it as a part of our lab setup.
\subsection{Mitigations}
\subsubsection{KASLR}
Address Space Layout Randomization (ASLR) is a common mechanism for mitigating
code-execution attacks in the context of user-level processes. To inject code into a
process, the attacker must know its memory layout (for example, the address of the code
section is required for finding ROP gadgets). Systems that support ASLR randomize the
memory layout for each process on every execution. In this way, regular attacks, which
are built for a specific layout, cannot work. Similarly, kASLR randomizes the memory
layout of the kernel, yet treats the entire kernel as a single region, randomizing only its
base address. Hence, knowing even one pointer is enough to deduce the base address.
Once the base address is known, the attacker can use it to patch the payload (first line of Listing 5.1).
In Linux, the high bits of every kernel pointer are always set to one. The specific number of bits depends on the region to which the pointer points. Even with
kASLR, pointers to the kernel binary region are always in the range [0xffffffff80000000,
0xffffffffc0000000) and, therefore, they are very easy to detect. In addition, since (at
least currently) kASLR works in multiplies of 2MB granularity, once a pointer is known,
it is also easy to conclude to which symbol in the binary it points. Malicious devices
can scan pages mapped for reading, looking for kernel pointers colocating with their
buffers. Once such a pointer is identified, all that remains is to reduce the offset of the
symbol in the binary from the pointer to get the base address.
We found that there is a symbol visible to both FireWire and NICs in all Linux
versions we tested, making it suitable for breaking kASLR. Starting from version
2.6.24, Linux supports network namespaces for isolating different instances of network
use. Every network object (and sockets, in particular) has a pointer to its namespace
object. Moreover, at least one namespace is always defined by the global object init net.
Since Tx packets have varying sizes, NICs can see all kinds of dynamically allocated
objects, including sockets. In addition, socket objects are about the same size as
sbp2 management orb, making them allocated from the same pages. Hence, both of
them can see socket objects and, thus also the address of init net. Using this pointer,
the attacker can deduce the base address and complete the attack.
In the case where we put the payload in a known page (e.g., FireWire), we are
done. In the other cases, we used the direct mapping to spray our payload—whether it
was using FTP, a user-level program or the NIC’s buffers. Starting from version 4.8,
the direct mapping base is also randomized (in alignment of at least 1GB), and it is
guaranteed to be in the range [0xffff880000000000, 0xffffc80000000000). Using a similar
technique, we read random colocated pointers we identified as belonging to that region,
finding our payload as well.

The current memory model of x86-64 linux servers is SPARSEMEM\_VMEMMAP \cite{mem_model}. Allowing easy transition between KVA - PFN - \page\footnote{Show fig with transitions}.
\subsubsection{NX-BIT}
As described in Chapter 4, we located the payload in a device-writeable page or in
a page belonging to the page cache. In both cases, this page is used to hold data
(rather than code, for example). Modern OSs make use of hardware support, namely
the No-eXecute bit, to prevent running code from these pages. The bit for each page is
defined in MMU’s page tables. Whenever the CPU tries to fetch code from memory, this
bit is checked. If it is set, instead of running the code, the CPU will raise an exception to the OS, notifying it that someone is trying to break into the system. This method is known under the names NX\-bit, W xor X (Write xor eXecute) and DEP.
Return Oriented Programming (ROP) Return Oriented Programming (ROP)
is a common method used by malware to bypass DEP defenses [RBSS12]. ROP takes
advantage of the fact that the CPU stack pointer may point to any data page. To set
up an attack from a data page, the attacker builds a stack filled with required data and
pointers to special locations in the code section (aka ROP gadgets) in it. Each gadget is
a short piece of code—usually one or two commands, and a return command. When the
CPU executes a return command, the next address to fetch code from is taken from the
stack. If the stack has been built correctly, the next address points to another gadget
and so on. By carefully selecting these gadgets, an attacker may run any payload. A
similar technique that uses jumps instead of returns—and, therefore, does not use the
stack—is called Jump Oriented Programming (JOP) [BJFL11].
\subsubsection{best practices}
I imagine a table with OS on Y and best practices on X.
IOMMU policy, KASLR, NX-bit, discriminate mapping (R or W, not both), device IOVA separation, sand boxing mapped addresses.
Kernels Win,MacOS,FreeBSD - use NDSS paper, contribution: ESX (Need to send some emails), Linux - Ubuntu versions, Sless?(RHEL).