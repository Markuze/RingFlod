
\section{RDMA}
We didnt find any risks associated with RDMA other than the methods listed in this paper, the ipoib driver also maps the \shinfo. But a malicious device is still needed, as the post\_send/post\_receive API is simmilar in function to the usual way NICs function; namely a remote user cant pick where to write or choose to write more than once to the same address. These kinds of operations are supported by rdma\_read/write API; which provides the peer the ability to read/write to a chosen addresses. We didn't find any uses for this kind of API in the Linux kernel. \textcolor{red}{AFAIK; besides Linux only Windows supports RDMA in the kernel}

\section{Related work}
\subsection{NDSS paper}
\textcolor{blue}{Page 13, when all else is done, may spend some lines to rip into the ndss paper}
\subsection{Protecting Against New attacks}
Deferred mode vulnerability could be mitigated by simply stopping batch IOTLB invalidations. To reduce performance overheads, one may batch the entire unmapping process rather than only the invalidation. Implementing such a solution will require a new memory management mechanism to keep the pages owned by the device. Implementing a page ownership mechanism could be beneficial for other cases as well, such as zero-copy buffers—which may be owned by one of the device, the kernel and user-level applications.
Sub-page vulnerability results from the gap between hardware design and software usages. Hence, it could be mitigated by modifying either the software or the hardware. Software modifications could be done either by repairing all broken drivers or, preferably, by changing the DMA layer so that it becomes aware of the size discrepancy. Hardware modification must be done centrally in the IOMMU in order to support legacy devices. Any solution that requires changes in I/O devices implies that secured environments could not include any currently existing device. In addition, common techniques against heap-overflow vulnerabilities might be used for making the attacks harder even though they will not completely eliminate them, as demonstrated above.
One possible software solution is to repair each and every driver that uses DMA. By making sure that drivers allocate memory for devices only in a page granularity, one could eliminate all sub-page issues. Even though this is probably the most obvious solution, it has the disadvantage of requiring a big change in existing code. In particular, legacy unsupported drivers must also be fixed to ensure that the system is truly secured. In addition, since every new driver should follow this guideline, the chance of creating new bugs is very high. This latter issue could be solved by additionally changing the DMA interface to accept only whole page mapping rather than arbitrary sized buffers.
Boyd-Wickizer and Zeldovich \cite{BWZ10} and LeVasseur et al. \cite{LUSG04} suggested isolating unmodified device drivers in user space programs and virtual machines, re- spectively. Similarly, Cinch used an isolated red virtual machine for intercepting bus traffic \cite{AWH16}. These methods could be applied to limit the damage of potential attacks in addition to other protection mechanisms. They do not, however, prevent code execution in the isolated environment. By attacking the isolation mechanism, attackers might still compromise the entire system.
Markuze et al. suggested that IOMMU driver should use bounce buffers \cite{MMT16}. Normally, device drivers invoke map/unmap requests for desired buffers through the DMA API. According to their suggestion, instead of dynamically mapping/unmapping pages, the DMA back-end would copy the buffer to/from designated pages with fixed mapping. By keeping separate data pages for each device, they avoid data colocation and, as a result, eliminate the sub-page granularity vulnerability. Since the mappings are static, the issue of deferred invalidation is eliminated as well. The advantage of this solution is that all code changes are centralized in the DMA layer. Nevertheless, this solution imposes huge overheads of data copying and memory wastage on the system. In a later work, Markuze et al. suggested reducing these overheads by implementing the DMA-Aware Malloc for Networking (DAMN) \cite{MSMT18}. DAMN allocates memory directly from the fixed-mapping pages, so there is no need to copy the buffers back and forth. This solution, however, requires code changes in the drivers and is not transparent.
Currently, there exist several hardware mechanisms for protecting CPU buffers smaller than a page. These mechanisms could be implemented in the IOMMU in order to mitigate the sub-page granularity vulnerability. Intel’s sup-page protecting technology suggests protecting fixed sized buffers smaller than a page \cite{Int18}. Since the buffers are still fixed sized, the same vulnerability remains, albeit in a more limited way. Intel MPX (Memory Protection Extensions) lets the user define boundaries for buffers and, later, explicitly checks that the corresponding pointers are between these boundaries \cite{Int16a}. Oracle SSM (Silicon Secured Memory) lets the user “color” buffers and associative pointers \cite{Ora15}. The color is implicitly checked for a match at each memory access. MPX, SSM and other similar approaches may be used for building a secure alternative for IOMMU. In practice, this means that the mappings are arbitrarily sized. An example of such an alternative is rIOMMU, which was designed to work optimally with network cards \cite{MABYT15}.Standard memory protection mechanisms include restriction of code executing areas and memory encryption. As we have shown above, DEP/kASLR do not prevent sub-page attacks. Encrypting sensitive data could prevent some forms of attacks (e.g., immediate data leakage). By leaking data using code that was injected by the DMA, Blass et al. have shown that encrypting sensitive data is not enough \cite{BR12}.
Common techniques against heap-overflow vulnerabilities may also be useful when they are properly implemented. For example, a recent Linux kernel patch suggests obfuscating the SLUB freelist by xor-ing its pointers with a random value \cite{Coo17}. This technique is very helpful in the case of simple heap overflow. In our scenario, however, the device was often able to read writable pages. Furthermore, old IOMMUs without special support of zero-length reads require writable pages to be readable as well \cite{Int16b}. Since the device can read the entire page, it is possible to deduce the random value from multiple obfuscated pointers. In contrast, obfuscating a single sensitive pointer poses a real difficulty to the exploiter even if the obfuscated pointer could be read first.
A completely different approach is to try to reduce the damage a working attack might cause rather than preventing it completely. This could be done by monitoring the behavior of devices and drivers for potential dangers. As with classic DMA attacks, monitoring the bus activity, looking for anomalies in DMA activity might be helpful for detecting live attacks \cite{Ste13}. This technique, however, still requires modeling each device DMA activity \cite{Ste14}. Similarly, monitoring mapping requests could be helpful during development. For example, one may look for known patterns, such as pointers or passwords, in a page during its mapping and detect bad practices in time.
\subsection{Additional Mitigations}
Intel control flow enforcement technology (CET) is a new instruction set for mitigating ROP attacks \cite{Int17}. Processors that support CET use two stacks simultaneously instead of the regular one, with the new shadow stack having only return addresses rather than a full copy of the data. During each RET command, the address in the shadow stack is checked and the code continues running only if the stacks agree on the address. Even if an attacker manages to control the regular stack, the shadow stack prevents the attack. In addition, each legitimate indirect jump target is marked with a special instruction. Thus, it is impossible to jump to arbitrary locations in the code and JOP attacks are also prevented. Similarly, each legitimate call target is also marked. De Raadt recently announced the Kernel Address Randomized Link (KARL) for FreeBSD as a software mitigation \cite{dr17}. Each time the system is booted, it links a new, randomized kernel binary. This is true randomization (as opposite to Linux’s kASLR), making it impossible to patch the payload during runtime. Both KARL and CET will successfully mitigate simple ROP/kASLR attacks whenever widely applied. 
